# 架构调度加速

## Prefix Caching

!!! note "KV Cache的跨请求复用"
    是prefill阶段的优化策略

## Chunked Prefill

[基于 chunked prefill 理解 prefill 和 decode 的计算特性 - 知乎](https://zhuanlan.zhihu.com/p/718715866)

[ai-infra-learning/lesson/05-chunked-prefills at main · cr7258/ai-infra-learning](https://github.com/cr7258/ai-infra-learning/tree/main/lesson/05-chunked-prefills)

### Continuous Batching

## PD分离架构



## FastChat 负载均衡

## Acknowledgement


- [cr7258/ai-infra-learning: This repository organizes materials, recordings, and schedules related to AI-infra learning meetings.](https://github.com/cr7258/ai-infra-learning/tree/main)